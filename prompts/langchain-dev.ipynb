{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain-core in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (0.3.41)\n",
      "Requirement already satisfied: langchain-community in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (1.0.1)\n",
      "Collecting grandalf\n",
      "  Using cached grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain-community) (2.5.2)\n",
      "Requirement already satisfied: pyparsing in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from grandalf) (3.1.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: anyio in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Using cached grandalf-0.8-py3-none-any.whl (41 kB)\n",
      "Installing collected packages: grandalf\n",
      "Successfully installed grandalf-0.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-core langchain-community python-dotenv grandalf\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv(\"./env/.env\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初步封装 -- SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain是一个用于构建基于语言的应用程序的开源框架，它可以帮助开发者更方便地使用大型语言模型（LLMs）和向量数据库。它提供了一套工具和库，使得构建复杂的人工智能应用程序变得更加容易。\\n\\n### 主要特性\\n\\n1. **与多种语言模型集成**：LangChain支持与各种语言模型进行集成，如OpenAI的GPT-3/4、Hugging Face的Transformers等。\\n2. **链式推理**：允许你创建复杂的逻辑流程，通过将多个任务链接在一起，实现更高级的功能。\\n3. **记忆功能**：内置的记忆机制可以保存对话历史，使聊天机器人能够记住之前的对话内容，提供更加连贯的交互体验。\\n4. **插件系统**：支持扩展，可以通过添加自定义插件来增强其功能。\\n5. **文档理解能力**：可以用来处理和理解大量的文本数据，比如从文档中提取信息或回答问题。\\n\\n### 应用场景\\n\\n- **聊天机器人**：构建具有上下文感知能力的聊天机器人。\\n- **知识管理系统**：帮助管理和检索大量文档中的信息。\\n- **自动化助手**：自动完成一些重复性的工作，如编写代码、生成报告等。\\n- **个性化推荐系统**：根据用户的兴趣和行为提供个性化的建议或内容。\\n\\n### 技术栈\\n\\nLangChain本身是用Python编写的，并且可以运行在任何支持Python的环境中。它利用了现有的AI库和API，如OpenAI的API、Hugging Face的Transformers等，来实现其功能。\\n\\n### 开发者社区\\n\\nLangChain拥有活跃的开发者社区，这意味着你可以很容易地找到帮助、教程和其他资源。此外，这个框架还在持续发展之中，经常会有新的更新和改进。\\n\\n总之，LangChain是一个强大而灵活的工具，适合那些希望利用大型语言模型开发复杂AI应用的开发者。' additional_kwargs={} response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': 'fc5d4ec1-382a-936a-9b9f-f72bd830ddaf', 'token_usage': {'input_tokens': 12, 'output_tokens': 397, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 409}} id='run-1753a797-7652-4848-b0c2-50396559063e-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "llm = ChatTongyi(temperature=1.0, model=\"qwen-turbo\", max_retries=50)\n",
    "response = llm.invoke(\"介绍一下langchain框架\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据抽象 -- IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain是一个用于构建基于语言的应用程序的Python库。它主要关注于构建基于大型语言模型（如GPT-3, BERT等）的应用程序。LangChain提供了许多工具和功能，使得开发者可以更容易地使用这些模型来处理文本数据。\n",
      "\n",
      "以下是LangChain的一些关键特性和组件：\n",
      "\n",
      "1. 文本分割：LangChain提供了一种将长文档分割成较小部分的方法。这对于需要处理大量文本数据的任务非常有用。\n",
      "\n",
      "2. 文本向量化：LangChain能够将文本转换为机器学习模型可以理解的向量形式。\n",
      "\n",
      "3. 向量存储：LangChain提供了一种存储和检索这些向量的方法，这使得在大量文本中搜索特定信息变得容易。\n",
      "\n",
      "4. 链接和检索：LangChain允许你链接多个模型或任务，并且可以在它们之间传递信息。同时，LangChain还提供了强大的检索功能，可以从大量的文本中快速找到相关信息。\n",
      "\n",
      "5. 集成其他服务：LangChain可以与许多其他服务集成，例如数据库、API等，使得你可以轻松地将这些服务纳入你的应用程序中。\n",
      "\n",
      "总的来说，LangChain是一个强大而灵活的框架，可以帮助开发者更方便地使用大型语言模型进行各种文本处理任务。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "# 创建LLM\n",
    "llm = ChatTongyi(temperature=1.0, model=\"qwen-turbo\", max_retries=50)\n",
    "\n",
    "# 创建Prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"{question}\")\n",
    "\n",
    "# 创建输出解析器\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 调用LLM\n",
    "message = prompt.invoke({\"question\": \"介绍一下langchain框架\"})\n",
    "response = llm.invoke(message)\n",
    "answer = output_parser.invoke(response)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 链式调用 -- chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain是一个用于构建基于语言的应用程序的开源框架。它旨在简化与大型语言模型（如GPT-3、BERT等）的交互，使开发者能够更方便地创建和部署基于这些模型的应用程序。\n",
      "\n",
      "以下是LangChain的一些主要特点：\n",
      "\n",
      "1. 易于集成：LangChain提供了一种简单的方式来连接各种语言模型，并且可以很容易地集成到现有的应用程序中。\n",
      "2. 模型抽象：LangChain提供了一层抽象，使得开发者可以更容易地使用不同的语言模型，而无需深入了解每个模型的具体细节。\n",
      "3. 可扩展性：LangChain设计为可扩展的，因此可以根据需要添加新的功能或支持新的模型。\n",
      "4. 社区支持：LangChain是一个开源项目，拥有活跃的社区支持，这意味着开发者可以获得帮助并参与到项目的开发中。\n",
      "\n",
      "使用LangChain，你可以快速地创建基于语言的应用程序，例如聊天机器人、文本生成器、问答系统等等。\n"
     ]
    }
   ],
   "source": [
    "# 创建Chain\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# 调用Chain\n",
    "answer = chain.invoke({\"question\": \"介绍一下langchain框架\"})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Runnablethrough Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain是一个用于构建语言模型应用程序的Python框架。它提供了一套工具和库，使得开发者能够更容易地使用大型语言模型（如GPT-3、BERT等）来创建聊天机器人、问答系统、文本生成器等应用。\n",
      "\n",
      "以下是LangChain的一些主要特点：\n",
      "\n",
      "1. 灵活的架构：LangChain允许用户根据自己的需求选择合适的语言模型，并且可以方便地替换不同的模型。\n",
      "2. 丰富的功能：LangChain提供了许多预处理和后处理工具，例如数据清洗、文本分割、错误处理等，这些都可以帮助开发者更轻松地处理各种任务。\n",
      "3. 集成API：LangChain集成了多种语言模型API，包括但不限于OpenAI的GPT系列、Hugging Face的Transformers等，这使得开发者可以轻松地访问这些强大的语言模型。\n",
      "4. 示例和教程：LangChain提供了一些示例代码和教程，可以帮助开发者快速上手并开始构建自己的语言模型应用程序。\n",
      "\n",
      "总之，LangChain是一个非常有用的工具，可以帮助开发者更轻松地利用大型语言模型的强大能力来构建各种应用程序。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 创建Chain\n",
    "chain = {\"question\": RunnablePassthrough()} | prompt | llm | output_parser\n",
    "\n",
    "# 调用Chain\n",
    "answer = chain.invoke(\"介绍一下langchain框架\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. DAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结来说，“蜜桃橙”这种水果结合了蜜桃和橙子的优点，可能具有以下好处：\n",
      "\n",
      "1. **高维生素含量**：富含维生素C和维生素A，增强免疫力和维护视力健康。\n",
      "2. **抗氧化剂**：含有丰富的抗氧化剂，有助于预防细胞损伤和抗衰老。\n",
      "3. **膳食纤维**：有助于消化，减少胆固醇吸收，保持肠道健康。\n",
      "4. **矿物质**：提供钾和其他矿物质，有助于维持心脏健康和血压稳定。\n",
      "5. **低热量**：适合减肥饮食，同时不会导致过多能量摄入。\n",
      "\n",
      "然而，过量食用也可能带来一些潜在的坏处：\n",
      "\n",
      "1. **过敏反应**：部分人群可能对其成分过敏。\n",
      "2. **消化不良**：过量食用可能导致腹胀、腹泻等消化问题。\n",
      "3. **糖分问题**：糖尿病患者需谨慎，因其含糖量较高。\n",
      "4. **口腔问题**：可能引发或加重口腔溃疡。\n",
      "5. **药物相互作用**：某些药物可能与柑橘类水果成分相互作用，影响药效。\n",
      "\n",
      "总体而言，适量食用“蜜桃橙”对人体是有益的，但如果有特殊健康状况或对某些成分敏感，建议咨询专业医生或营养师。\n",
      "                                   +-------------+                               \n",
      "                                   | PromptInput |                               \n",
      "                                   +-------------+                               \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                               +--------------------+                            \n",
      "                               | ChatPromptTemplate |                            \n",
      "                               +--------------------+                            \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                   +------------+                                \n",
      "                                   | ChatTongyi |                                \n",
      "                                   +------------+                                \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                 +-----------------+                             \n",
      "                                 | StrOutputParser |                             \n",
      "                                 +-----------------+                             \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                              +-----------------------+                          \n",
      "                              | StrOutputParserOutput |                          \n",
      "                              +-----------------------+                          \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                   +-------------+                               \n",
      "                                   | Passthrough |                               \n",
      "                                   +-------------+                               \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                          +-------------------------------+                      \n",
      "                          | Parallel<good,bad,topic>Input |                      \n",
      "                          +-------------------------------+                      \n",
      "                        ******            *             *****                    \n",
      "                   *****                   *                 *****               \n",
      "                ***                        *                      ******         \n",
      "+--------------------+          +--------------------+                  ***      \n",
      "| ChatPromptTemplate |          | ChatPromptTemplate |                    *      \n",
      "+--------------------+          +--------------------+                    *      \n",
      "           *                               *                              *      \n",
      "           *                               *                              *      \n",
      "           *                               *                              *      \n",
      "    +------------+                  +------------+                        *      \n",
      "    | ChatTongyi |                  | ChatTongyi |                        *      \n",
      "    +------------+                  +------------+                        *      \n",
      "           *                               *                              *      \n",
      "           *                               *                              *      \n",
      "           *                               *                              *      \n",
      "  +-----------------+             +-----------------+               +--------+   \n",
      "  | StrOutputParser |             | StrOutputParser |             **| Lambda |   \n",
      "  +-----------------+***          +-----------------+        *****  +--------+   \n",
      "                        ******             *           ******                    \n",
      "                              *****       *       *****                          \n",
      "                                   ***    *    ***                               \n",
      "                         +--------------------------------+                      \n",
      "                         | Parallel<good,bad,topic>Output |                      \n",
      "                         +--------------------------------+                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                               +--------------------+                            \n",
      "                               | ChatPromptTemplate |                            \n",
      "                               +--------------------+                            \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                   +------------+                                \n",
      "                                   | ChatTongyi |                                \n",
      "                                   +------------+                                \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                 +-----------------+                             \n",
      "                                 | StrOutputParser |                             \n",
      "                                 +-----------------+                             \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                                          *                                      \n",
      "                              +-----------------------+                          \n",
      "                              | StrOutputParserOutput |                          \n",
      "                              +-----------------------+                          \n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "# 创建LLM\n",
    "llm = ChatTongyi(temperature=1.0, model=\"qwen-turbo\", max_retries=50)\n",
    "\n",
    "# 创建输出解析器\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 创建Prompt\n",
    "topic_prompt = ChatPromptTemplate.from_template(\"生成一种'{input}'的名称\")\n",
    "good_prompt = ChatPromptTemplate.from_template(\"列举{topic}的好处:\")\n",
    "bad_prompt = ChatPromptTemplate.from_template(\"列举{topic}的坏处:\")\n",
    "summary_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"生成最终结论\"),\n",
    "        (\"ai\", \"{topic}\"),\n",
    "        (\"human\", \"好处:\\n{good}\\n\\n坏处:\\n{bad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 创建组合Chain\n",
    "topic_chain = topic_prompt | llm | output_parser | {\"topic\": RunnablePassthrough()}\n",
    "goods_chain = good_prompt | llm | output_parser\n",
    "bads_chain = bad_prompt | llm | output_parser\n",
    "summary_chain = summary_prompt | llm | output_parser\n",
    "chain = (\n",
    "    topic_chain\n",
    "    | {\n",
    "        \"good\": goods_chain,\n",
    "        \"bad\": bads_chain,\n",
    "        \"topic\": itemgetter(\"topic\"),\n",
    "    }\n",
    "    | summary_chain\n",
    ")\n",
    "\n",
    "# 调用chain\n",
    "answer = chain.invoke({\"input\": \"常见水果\"})\n",
    "print(answer)\n",
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "杭州\n",
      "[HumanMessage(content='杭州的气温是多少?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'name': 'get_temperature', 'arguments': '{\"city\": \"杭州\"}'}, 'index': 0, 'id': 'call_b1ffe6ef92534b0f8085ec', 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '106d6ff1-cb6b-9f16-8a40-f131f4f8e1e9', 'token_usage': {'input_tokens': 163, 'output_tokens': 17, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 180}}, id='run-81b35cc3-057b-4626-baa5-ae4ca064fd30-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': '杭州'}, 'id': 'call_b1ffe6ef92534b0f8085ec', 'type': 'tool_call'}]), ToolMessage(content='50', name='get_temperature', tool_call_id='call_b1ffe6ef92534b0f8085ec')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='杭州现在的气温是50℃。这个温度异常高，通常情况下地球表面的气温不会达到这么高，可能是获取到的数据有误。请让我再次确认一下。', additional_kwargs={'tool_calls': [{'function': {'name': 'get_temperature', 'arguments': '{\"city\": \"杭州\"}'}, 'index': 0, 'id': 'call_5a26194c516b4833893f9c', 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '9bbde9d3-bd35-95f0-aedf-a237d183c293', 'token_usage': {'input_tokens': 191, 'output_tokens': 57, 'prompt_tokens_details': {'cached_tokens': 128}, 'total_tokens': 248}}, id='run-cc569038-6dc1-4c30-9e01-77f2d5605338-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': '杭州'}, 'id': 'call_5a26194c516b4833893f9c', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "\n",
    "# 定义Tool\n",
    "@tool\n",
    "def get_temperature(city: str) -> int:\n",
    "    \"\"\"获取指定城市的当前气温\"\"\"\n",
    "    print(city)\n",
    "    return random.randint(-20, 50)\n",
    "\n",
    "\n",
    "# 创建LLM\n",
    "llm = ChatTongyi(temperature=1.0, model=\"qwen-turbo\", max_retries=50, verbose=True)\n",
    "\n",
    "# 创建JSON输出解析器\n",
    "output_parser = JsonOutputToolsParser()\n",
    "\n",
    "# 创建Chain\n",
    "chain = llm.bind_tools(tools=[get_temperature])\n",
    "\n",
    "# 调用Chain\n",
    "query = \"杭州的气温是多少?\"\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = chain.invoke(\"杭州的温度是多少?\")\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"get_temperature\": get_temperature}[tool_call[\"name\"].lower()]\n",
    "    tool_message = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_message)\n",
    "\n",
    "print(messages)\n",
    "\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
