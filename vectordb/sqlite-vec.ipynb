{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlite-vec in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (0.1.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sqlite-vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_version=v0.1.6\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import sqlite_vec\n",
    "\n",
    "db = sqlite3.connect(\"memory-test-vector.db\")\n",
    "db.enable_load_extension(True)\n",
    "sqlite_vec.load(db)\n",
    "db.enable_load_extension(False)\n",
    "\n",
    "(vec_version,) = db.execute(\"select vec_version()\").fetchone()\n",
    "print(f\"vec_version={vec_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from sqlite_vec import serialize_float32\n",
    "\n",
    "embedding = [0.1, 0.2, 0.3, 0.4]\n",
    "result = db.execute(\"select vec_length(?)\", [serialize_float32(embedding)])\n",
    "\n",
    "print(result.fetchone()[0])  # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite_version=3.41.1, vec_version=v0.1.6\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "table vec_items already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 29\u001b[0m\n\u001b[1;32m     20\u001b[0m items \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     21\u001b[0m     (\u001b[38;5;241m1\u001b[39m, [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]),\n\u001b[1;32m     22\u001b[0m     (\u001b[38;5;241m2\u001b[39m, [\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.2\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     (\u001b[38;5;241m5\u001b[39m, [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m]),\n\u001b[1;32m     26\u001b[0m ]\n\u001b[1;32m     27\u001b[0m query \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.3\u001b[39m]\n\u001b[0;32m---> 29\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE VIRTUAL TABLE vec_items USING vec0(embedding float[4])\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m db:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items:\n",
      "\u001b[0;31mOperationalError\u001b[0m: table vec_items already exists"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import struct\n",
    "\n",
    "\n",
    "def serialize_f32(vector: List[float]) -> bytes:\n",
    "    \"\"\"serializes a list of floats into a compact \"raw bytes\" format\"\"\"\n",
    "    return struct.pack(\"%sf\" % len(vector), *vector)\n",
    "\n",
    "# memory sqlite db\n",
    "#db = sqlite3.connect(\":memory:\")\n",
    "#db.enable_load_extension(True)\n",
    "#sqlite_vec.load(db)\n",
    "#db.enable_load_extension(False)\n",
    "\n",
    "sqlite_version, vec_version = db.execute(\n",
    "    \"select sqlite_version(), vec_version()\"\n",
    ").fetchone()\n",
    "print(f\"sqlite_version={sqlite_version}, vec_version={vec_version}\")\n",
    "\n",
    "items = [\n",
    "    (1, [0.1, 0.1, 0.1, 0.1]),\n",
    "    (2, [0.2, 0.2, 0.2, 0.2]),\n",
    "    (3, [0.3, 0.3, 0.3, 0.3]),\n",
    "    (4, [0.4, 0.4, 0.4, 0.4]),\n",
    "    (5, [0.5, 0.5, 0.5, 0.5]),\n",
    "]\n",
    "query = [0.3, 0.3, 0.3, 0.3]\n",
    "\n",
    "db.execute(\"CREATE VIRTUAL TABLE vec_items USING vec0(embedding float[4])\")\n",
    "\n",
    "with db:\n",
    "    for item in items:\n",
    "        db.execute(\n",
    "            \"INSERT INTO vec_items(rowid, embedding) VALUES (?, ?)\",\n",
    "            [item[0], serialize_f32(item[1])],\n",
    "        )\n",
    "\n",
    "rows = db.execute(\n",
    "    \"\"\"\n",
    "      SELECT\n",
    "        rowid,\n",
    "        distance\n",
    "      FROM vec_items\n",
    "      WHERE embedding MATCH ?\n",
    "      ORDER BY distance\n",
    "      LIMIT 3\n",
    "    \"\"\",\n",
    "    [serialize_f32(query)],\n",
    ").fetchall()\n",
    "\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ok'\n",
      "[0.022378576171554372, -0.027432455162420308, -0.00355793080956962]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv(\"./env/.env\"))\n",
    "\n",
    "import dashscope\n",
    "from http import HTTPStatus\n",
    "from pprint import pprint\n",
    "\n",
    "with open(\"来自 Google 内部的另外一种声音：AI 没有护城河.md\", 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "resp = dashscope.TextEmbedding.call(\n",
    "    model=dashscope.TextEmbedding.Models.text_embedding_v2,\n",
    "    input=\"We are lucky to live in an age in which we are still making discoveries.\",\n",
    "    dimension=1536,\n",
    ")\n",
    "pprint(\"ok\") if resp.status_code == HTTPStatus.OK else print(resp)\n",
    "pprint(resp[\"output\"][\"embeddings\"][0][\"embedding\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from tiktoken) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18182\n",
      "5457\n",
      "chunk items length:  3\n",
      "length:  6061\n",
      "length:  6061\n",
      "length:  6060\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "def batched(iterable, n):\n",
    "    \"\"\"将数据分批处理成每批长度为 n 的元组。最后一批的长度可能较短。\"\"\"\n",
    "    # batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be at least one\")\n",
    "    it = iter(iterable)\n",
    "    while batch := islice(it, n):\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def chunked_tokens(text, encoding_name, chunk_length):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(text)\n",
    "    chunk_items_len = len(tokens) // chunk_length + 1\n",
    "    print(\"chunk items length: \", chunk_items_len)\n",
    "    text_len = len(text) // chunk_items_len + 1\n",
    "    chunks_iterator = [text[i : i + text_len] for i in range(0, len(text), text_len)]\n",
    "    yield from chunks_iterator\n",
    "\n",
    "\n",
    "def len_safe_get_embedding(\n",
    "    text,\n",
    "    model=\"text-embedding-v2\",\n",
    "    max_tokens=2048,\n",
    "    encoding_name=\"cl100k_base\",\n",
    "):\n",
    "    chunk_embeddings = []\n",
    "    chunk_lens = []\n",
    "    for chunk in chunked_tokens(\n",
    "        text, encoding_name=encoding_name, chunk_length=max_tokens\n",
    "    ):\n",
    "        print(\"length: \", len(chunk))\n",
    "        chunk_embeddings.append(get_embedding(chunk, model=model))\n",
    "        chunk_lens.append(len(chunk))\n",
    "\n",
    "    chunk_embeddings = np.average(chunk_embeddings, axis=0, weights=chunk_lens)\n",
    "    return chunk_embeddings\n",
    "\n",
    "def get_embedding(text, model):\n",
    "    resp = dashscope.TextEmbedding.call(\n",
    "        model=model,\n",
    "        input=text,\n",
    "        dimension=1024,\n",
    "    )\n",
    "    return resp[\"output\"][\"embeddings\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "print(len(text))\n",
    "tokens = tiktoken.get_encoding(\"cl100k_base\").encode(text)\n",
    "print(len(tokens))\n",
    "chunked_embeddings = len_safe_get_embedding(text)\n",
    "print(len(chunked_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18182\n",
      "[-0.07153698801994324, -0.04376567527651787, -0.030815014615654945, -0.006778706330806017, -0.06811530888080597]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(text))\n",
    "resp_v3 = dashscope.TextEmbedding.call(\n",
    "    model=dashscope.TextEmbedding.Models.text_embedding_v3,\n",
    "    input=text,\n",
    "    dimension=1024,\n",
    ")\n",
    "print(resp_v3[\"output\"][\"embeddings\"][0]['embedding'][:5])\n",
    "embeddings = resp_v3[\"output\"][\"embeddings\"]\n",
    "print(len(embeddings))\n",
    "\n",
    "# resp_batched = dashscope.BatchTextEmbedding.call(\n",
    "#    model=dashscope.BatchTextEmbedding.Models.text_embedding_async_v2,\n",
    "#    url=\"https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20241016/nigwvr/text_embedding_file.txt\",\n",
    "#    text_type=\"document\"\n",
    "# )\n",
    "# pprint(resp_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07153698801994324, -0.04376567527651787, -0.030815014615654945, -0.006778706330806017, -0.06811530888080597]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings[0][\"embedding\"][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x10e9603c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute(\n",
    "    \"\"\"CREATE VIRTUAL TABLE if NOT EXISTS vec_document_items USING vec0(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    document_name TEXT,\n",
    "    embedding float[1024]\n",
    ")\"\"\"\n",
    ")\n",
    "\n",
    "id = 1\n",
    "name = \"./vectordb/来自 Google 内部的另外一种声音：AI 没有护城河.md\"\n",
    "vector = embeddings[0][\"embedding\"]\n",
    "\n",
    "db.execute(\n",
    "    \"INSERT INTO vec_document_items(id, document_name, embedding) VALUES (?, ?, ?)\",\n",
    "    [id, name, serialize_f32(vector)],\n",
    ")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\n",
    "    \"\"\"CREATE VIRTUAL TABLE if NOT EXISTS vec_chunked_document_items USING vec0(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    document_name TEXT,\n",
    "    embedding float[1536]\n",
    ")\"\"\"\n",
    ")\n",
    "with db:\n",
    "    for id, embedding in enumerate(chunked_embeddings):\n",
    "        db.execute(\n",
    "            \"INSERT INTO vec_chunked_document_items(id, document_name, embedding) VALUES (?, ?, ?)\",\n",
    "            [id, name, serialize_f32(embedding)],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "UNIQUE constraint failed on vec_chunked_document_items primary key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m db:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunked_embeddings):\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mINSERT INTO vec_chunked_document_items(id, document_name, embedding) VALUES (?, ?, ?)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialize_f32\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOperationalError\u001b[0m: UNIQUE constraint failed on vec_chunked_document_items primary key"
     ]
    }
   ],
   "source": [
    "# insert again\n",
    "with db:\n",
    "    for id, embedding in enumerate(chunked_embeddings):\n",
    "        db.execute(\n",
    "            \"INSERT INTO vec_chunked_document_items(id, document_name, embedding) VALUES (?, ?, ?)\",\n",
    "            [id, name, serialize_f32(embedding)],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
