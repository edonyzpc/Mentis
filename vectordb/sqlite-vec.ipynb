{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlite-vec in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (0.1.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sqlite-vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_version=v0.1.6\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import sqlite_vec\n",
    "\n",
    "db = sqlite3.connect(\"memory-test-vector.db\")\n",
    "db.enable_load_extension(True)\n",
    "sqlite_vec.load(db)\n",
    "db.enable_load_extension(False)\n",
    "\n",
    "(vec_version,) = db.execute(\"select vec_version()\").fetchone()\n",
    "print(f\"vec_version={vec_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from sqlite_vec import serialize_float32\n",
    "\n",
    "embedding = [0.1, 0.2, 0.3, 0.4]\n",
    "result = db.execute(\"select vec_length(?)\", [serialize_float32(embedding)])\n",
    "\n",
    "print(result.fetchone()[0])  # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite_version=3.41.1, vec_version=v0.1.6\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "table vec_items already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 29\u001b[0m\n\u001b[1;32m     20\u001b[0m items \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     21\u001b[0m     (\u001b[38;5;241m1\u001b[39m, [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]),\n\u001b[1;32m     22\u001b[0m     (\u001b[38;5;241m2\u001b[39m, [\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.2\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     (\u001b[38;5;241m5\u001b[39m, [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m]),\n\u001b[1;32m     26\u001b[0m ]\n\u001b[1;32m     27\u001b[0m query \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.3\u001b[39m]\n\u001b[0;32m---> 29\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE VIRTUAL TABLE vec_items USING vec0(embedding float[4])\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m db:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items:\n",
      "\u001b[0;31mOperationalError\u001b[0m: table vec_items already exists"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import struct\n",
    "\n",
    "\n",
    "def serialize_f32(vector: List[float]) -> bytes:\n",
    "    \"\"\"serializes a list of floats into a compact \"raw bytes\" format\"\"\"\n",
    "    return struct.pack(\"%sf\" % len(vector), *vector)\n",
    "\n",
    "# memory sqlite db\n",
    "#db = sqlite3.connect(\":memory:\")\n",
    "#db.enable_load_extension(True)\n",
    "#sqlite_vec.load(db)\n",
    "#db.enable_load_extension(False)\n",
    "\n",
    "sqlite_version, vec_version = db.execute(\n",
    "    \"select sqlite_version(), vec_version()\"\n",
    ").fetchone()\n",
    "print(f\"sqlite_version={sqlite_version}, vec_version={vec_version}\")\n",
    "\n",
    "items = [\n",
    "    (1, [0.1, 0.1, 0.1, 0.1]),\n",
    "    (2, [0.2, 0.2, 0.2, 0.2]),\n",
    "    (3, [0.3, 0.3, 0.3, 0.3]),\n",
    "    (4, [0.4, 0.4, 0.4, 0.4]),\n",
    "    (5, [0.5, 0.5, 0.5, 0.5]),\n",
    "]\n",
    "query = [0.3, 0.3, 0.3, 0.3]\n",
    "\n",
    "db.execute(\"CREATE VIRTUAL TABLE vec_items USING vec0(embedding float[4])\")\n",
    "\n",
    "with db:\n",
    "    for item in items:\n",
    "        db.execute(\n",
    "            \"INSERT INTO vec_items(rowid, embedding) VALUES (?, ?)\",\n",
    "            [item[0], serialize_f32(item[1])],\n",
    "        )\n",
    "\n",
    "rows = db.execute(\n",
    "    \"\"\"\n",
    "      SELECT\n",
    "        rowid,\n",
    "        distance\n",
    "      FROM vec_items\n",
    "      WHERE embedding MATCH ?\n",
    "      ORDER BY distance\n",
    "      LIMIT 3\n",
    "    \"\"\",\n",
    "    [serialize_f32(query)],\n",
    ").fetchall()\n",
    "\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ok'\n",
      "[0.022378576171554372, -0.027432455162420308, -0.00355793080956962]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv(\"./env/.env\"))\n",
    "\n",
    "import dashscope\n",
    "from http import HTTPStatus\n",
    "from pprint import pprint\n",
    "\n",
    "with open(\"来自 Google 内部的另外一种声音：AI 没有护城河.md\", 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "resp = dashscope.TextEmbedding.call(\n",
    "    model=dashscope.TextEmbedding.Models.text_embedding_v2,\n",
    "    input=\"We are lucky to live in an age in which we are still making discoveries.\",\n",
    "    dimension=1536,\n",
    ")\n",
    "pprint(\"ok\") if resp.status_code == HTTPStatus.OK else print(resp)\n",
    "pprint(resp[\"output\"][\"embeddings\"][0][\"embedding\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from tiktoken) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18182\n",
      "5457\n",
      "chunk items length:  3\n",
      "length:  6061\n",
      "length:  6061\n",
      "length:  6060\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "def batched(iterable, n):\n",
    "    \"\"\"将数据分批处理成每批长度为 n 的元组。最后一批的长度可能较短。\"\"\"\n",
    "    # batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be at least one\")\n",
    "    it = iter(iterable)\n",
    "    while batch := islice(it, n):\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def chunked_tokens(text, encoding_name, chunk_length):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(text)\n",
    "    chunk_items_len = len(tokens) // chunk_length + 1\n",
    "    print(\"chunk items length: \", chunk_items_len)\n",
    "    text_len = len(text) // chunk_items_len + 1\n",
    "    chunks_iterator = [text[i : i + text_len] for i in range(0, len(text), text_len)]\n",
    "    yield from chunks_iterator\n",
    "\n",
    "\n",
    "def len_safe_get_embedding(\n",
    "    text,\n",
    "    model=\"text-embedding-v2\",\n",
    "    max_tokens=2048,\n",
    "    encoding_name=\"cl100k_base\",\n",
    "):\n",
    "    chunk_embeddings = []\n",
    "    chunk_lens = []\n",
    "    for chunk in chunked_tokens(\n",
    "        text, encoding_name=encoding_name, chunk_length=max_tokens\n",
    "    ):\n",
    "        print(\"length: \", len(chunk))\n",
    "        chunk_embeddings.append(get_embedding(chunk, model=model))\n",
    "        chunk_lens.append(len(chunk))\n",
    "\n",
    "    chunk_embeddings = np.average(chunk_embeddings, axis=0, weights=chunk_lens)\n",
    "    return chunk_embeddings\n",
    "\n",
    "def get_embedding(text, model):\n",
    "    resp = dashscope.TextEmbedding.call(\n",
    "        model=model,\n",
    "        input=text,\n",
    "        dimension=1024,\n",
    "    )\n",
    "    return resp[\"output\"][\"embeddings\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "print(len(text))\n",
    "tokens = tiktoken.get_encoding(\"cl100k_base\").encode(text)\n",
    "print(len(tokens))\n",
    "chunked_embeddings = len_safe_get_embedding(text)\n",
    "print(len(chunked_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18182\n",
      "[-0.07153698801994324, -0.04376567527651787, -0.030815014615654945, -0.006778706330806017, -0.06811530888080597]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(text))\n",
    "resp_v3 = dashscope.TextEmbedding.call(\n",
    "    model=dashscope.TextEmbedding.Models.text_embedding_v3,\n",
    "    input=text,\n",
    "    dimension=1024,\n",
    ")\n",
    "print(resp_v3[\"output\"][\"embeddings\"][0]['embedding'][:5])\n",
    "embeddings = resp_v3[\"output\"][\"embeddings\"]\n",
    "print(len(embeddings))\n",
    "\n",
    "# resp_batched = dashscope.BatchTextEmbedding.call(\n",
    "#    model=dashscope.BatchTextEmbedding.Models.text_embedding_async_v2,\n",
    "#    url=\"https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20241016/nigwvr/text_embedding_file.txt\",\n",
    "#    text_type=\"document\"\n",
    "# )\n",
    "# pprint(resp_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07153698801994324, -0.04376567527651787, -0.030815014615654945, -0.006778706330806017, -0.06811530888080597]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings[0][\"embedding\"][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x10e9603c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute(\n",
    "    \"\"\"CREATE VIRTUAL TABLE if NOT EXISTS vec_document_items USING vec0(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    document_name TEXT,\n",
    "    embedding float[1024]\n",
    ")\"\"\"\n",
    ")\n",
    "\n",
    "id = 1\n",
    "name = \"./vectordb/来自 Google 内部的另外一种声音：AI 没有护城河.md\"\n",
    "vector = embeddings[0][\"embedding\"]\n",
    "\n",
    "db.execute(\n",
    "    \"INSERT INTO vec_document_items(id, document_name, embedding) VALUES (?, ?, ?)\",\n",
    "    [id, name, serialize_f32(vector)],\n",
    ")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\n",
    "    \"\"\"CREATE VIRTUAL TABLE if NOT EXISTS vec_chunked_document_items USING vec0(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    document_name TEXT,\n",
    "    embedding float[1536]\n",
    ")\"\"\"\n",
    ")\n",
    "with db:\n",
    "    for id, embedding in enumerate(chunked_embeddings):\n",
    "        db.execute(\n",
    "            \"INSERT INTO vec_chunked_document_items(id, document_name, embedding) VALUES (?, ?, ?)\",\n",
    "            [id, name, serialize_f32(embedding)],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "UNIQUE constraint failed on vec_chunked_document_items primary key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m db:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunked_embeddings):\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mINSERT INTO vec_chunked_document_items(id, document_name, embedding) VALUES (?, ?, ?)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialize_f32\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOperationalError\u001b[0m: UNIQUE constraint failed on vec_chunked_document_items primary key"
     ]
    }
   ],
   "source": [
    "# insert again\n",
    "with db:\n",
    "    for id, embedding in enumerate(chunked_embeddings):\n",
    "        db.execute(\n",
    "            \"INSERT INTO vec_chunked_document_items(id, document_name, embedding) VALUES (?, ?, ?)\",\n",
    "            [id, name, serialize_f32(embedding)],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (3.4.1)\n",
      "Collecting sqlite-vss\n",
      "  Downloading sqlite_vss-0.1.2-py3-none-macosx_11_0_arm64.whl.metadata (494 bytes)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain-text-splitters) (0.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from sentence-transformers) (0.24.6)\n",
      "Requirement already satisfied: Pillow in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (0.1.120)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (8.3.0)\n",
      "Requirement already satisfied: networkx in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: anyio in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (1.2.2)\n",
      "Downloading sqlite_vss-0.1.2-py3-none-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sqlite-vss\n",
      "Successfully installed sqlite-vss-0.1.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-text-splitters sentence-transformers sqlite-vss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='最近读到一篇去年泄漏的Google内部研究员的文件，要提前说明的是这份文件中的观点从现在来看是有待商榷的，但是它确实提供了另外一个观察这波 AI 浪潮的视角，让个人开发者甚至中小企业思考如何参与这一次技术革新。' metadata={'Header 1': '来自 Google 内部的另外一种声音：AI 没有护城河'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'行业数据（如安全、金融、医疗）具有高度的专业性且难以获取，形成了一定的数据壁垒，高质量的数据标注需要大量的人力物力，这使得别人难以追赶。同时优秀的 AI 算法往往涉及复杂的数学模型和优化技术，需要高水平的人才，而对特定场景的模型微调需要大量的实验和经验积累，从而导致AI人才供不应求。最后AI模型训练需要大量的计算资源，需要更强大的算力基础设施。  \\n与此同时，TensorFlow、PyTorch 等开源框架降低了 AI 开发的门槛，使得技术更容易被复制。预训练模型的共享加速了模型开发，缩短了模型训练时间。 AI 领域技术更新迭代迅速，算法的领先优势可能很快被超越。云计算的发展降低了算力获取的成本，使得获得足够的算力的门槛降低。越来越严格的数据隐私法规限制了数据的获取和利用，削弱了数据壁垒。  \\n正式这样复杂的优势与局限导致：\\n- 强者恒强： 拥有雄厚资金实力的科技巨头将在AI竞争中占据主导地位。\\n- 同质化竞争加剧： 各家公司推出的AI产品同质化严重，差异化竞争不足。\\n- 硬件受限： AI硬件的核心技术被少数几家公司垄断，中小公司难以在硬件领域取得突破。'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import SQLiteVSS\n",
    "from langchain_text_splitters import CharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "# init qwen model config\n",
    "_ = load_dotenv(find_dotenv(\"./env/.env\"))\n",
    "\n",
    "# load the document and split it into chunks\n",
    "loader = TextLoader(\"./来自 Google 内部的另外一种声音：AI 没有护城河.md\")\n",
    "documents = loader.load()\n",
    "with open(\"./来自 Google 内部的另外一种声音：AI 没有护城河.md\", \"r\") as f:\n",
    "    md_str = f.read()\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n",
    "markdown_text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "md_docs = markdown_text_splitter.split_text(md_str)\n",
    "texts = [doc.page_content for doc in docs]\n",
    "md_texts = [md_doc.page_content for md_doc in md_docs]\n",
    "print(md_docs[1])\n",
    "\n",
    "\n",
    "# create the open-source embedding function\n",
    "# embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "embedding_function = DashScopeEmbeddings(model=\"text-embedding-v3\")\n",
    "\n",
    "\n",
    "# load it in sqlite-vss in a table named state_union.\n",
    "# the db_file parameter is the name of the file you want\n",
    "# as your sqlite database.\n",
    "db = SQLiteVSS.from_texts(\n",
    "    texts=md_texts,\n",
    "    embedding=embedding_function,\n",
    "    table=\"state_union\",\n",
    "    db_file=\"./vss.db\",\n",
    ")\n",
    "\n",
    "# query it\n",
    "query = \"AI的壁垒没有想象中的那么高\"\n",
    "data = db.similarity_search(query)\n",
    "\n",
    "# print results\n",
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={}, page_content='行业数据（如安全、金融、医疗）具有高度的专业性且难以获取，形成了一定的数据壁垒，高质量的数据标注需要大量的人力物力，这使得别人难以追赶。同时优秀的 AI 算法往往涉及复杂的数学模型和优化技术，需要高水平的人才，而对特定场景的模型微调需要大量的实验和经验积累，从而导致AI人才供不应求。最后AI模型训练需要大量的计算资源，需要更强大的算力基础设施。  \\n与此同时，TensorFlow、PyTorch 等开源框架降低了 AI 开发的门槛，使得技术更容易被复制。预训练模型的共享加速了模型开发，缩短了模型训练时间。 AI 领域技术更新迭代迅速，算法的领先优势可能很快被超越。云计算的发展降低了算力获取的成本，使得获得足够的算力的门槛降低。越来越严格的数据隐私法规限制了数据的获取和利用，削弱了数据壁垒。  \\n正式这样复杂的优势与局限导致：\\n- 强者恒强： 拥有雄厚资金实力的科技巨头将在AI竞争中占据主导地位。\\n- 同质化竞争加剧： 各家公司推出的AI产品同质化严重，差异化竞争不足。\\n- 硬件受限： AI硬件的核心技术被少数几家公司垄断，中小公司难以在硬件领域取得突破。'),\n",
       "  0.5443615913391113),\n",
       " (Document(metadata={}, page_content='尽管 Google 研究员认为 AI 行业强者恒强、同质化竞争剧烈，但仍可以从以下几个方面探讨如何建立潜在的护城河，特别是对个人和中小企业而言：\\n- 数据质量： 优质、标注精细的数据是训练AI模型的关键。拥有高质量数据的公司可能具备一定优势。 专注于特定行业，积累行业知识和数据，形成深厚的技术壁垒。\\n- 工程创新： 虽然核心算法是开源的，但对算法的工程优化和创新仍然是提升模型性能的重要途径。 持续投入研究，不断突破提升使用体验也可以保持领先。\\n- Know-How： 将 AI 技术与特定行业深度结合，积累行业Know-How，可以形成一定的竞争壁垒。\\n- 人才团队： 拥有优秀的 AI 人才团队，能够持续进行创新和研发，也是一种护城河。'),\n",
       "  0.6289268732070923),\n",
       " (Document(metadata={}, page_content='AI 行业是一个典型的完全竞争行业，想要在 AI 领域取得领先优势，巨额的资金投入是必不可少的。算力、数据、人才是决定胜负的关键因素。对于个人、中小公司而言，想要在 AI 领域突围，难度较大。AI行业竞争激烈，护城河薄弱，资源决定成败：\\n- 技术开源易获取： 生成式AI的核心技术是开源的，任何人都能获取并搭建模型，降低了技术门槛。\\n- 模型易替代性强： 各家模型功能相似，差异不大，容易被替代。新功能的推出很快会被竞争对手追赶。\\n- 算力和数据决定成败： 拥有更强大的算力和更丰富的训练数据是提升模型性能的关键。然而，算力和数据都依赖于经济实力，容易被模仿。\\n- 人才流动性大： AI 研究人员流动性高，知识共享频繁，使得技术进步迅速。\\n- 版权问题相对宽松： 欧美判例表明，在不构成直接复制的情况下，可以自由使用版权材料进行训练，降低了数据获取的难度。'),\n",
       "  0.6472592949867249),\n",
       " (Document(metadata={}, page_content='---\\ntitle: 来自 Google 内部的另外一种声音：AI 没有护城河\\ndate: 2024-08-17 18:57:43\\nmodify: 2024-08-17 18:59:23\\nauthor: edony.zpc\\ntags:\\naliases:\\nfeatured: false\\npublished: false\\nexcerpt: Google内部研究报告指出，技术开源、模型易替代、算力与数据依赖经济实力等因素加剧了AI行业竞争，这导致强者恒强。然而对于个人和中小企业而言，AI行业仍存在机遇，应聚焦细分领域，避开与巨头正面竞争。 通过深入行业，积累专业知识和数据，并注重用户体验的优化在特定领域取得突破进而形成专属的「护城河」\\nfeature_image: \"\"\\n---\\n%%\\nsubject: #004-topics #blogging\\nstatus: #published\\ntype:\\nexcerpt:\\nrelated: [[AI 没有护城河]]\\n%%'),\n",
       "  0.6703628301620483)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5457 tokens\n",
      "11192 2150\n",
      "5457 tokens exceeds the maximum of 2048 tokens\n",
      "5457 tokens need to chunk\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "MODEL_2_ENCODING = {\"text-embedding-v1\": \"cl100k_base\", \"text-embedding-v2\": \"cl100k_base\", \"text-embedding-v3\": \"cl100k_base\"}\n",
    "MAX_TOKEN = {\"text-embedding-v1\": 2048, \"text-embedding-v2\": 2048, \"text-embedding-v3\":8192}\n",
    "\n",
    "model_name = \"text-embedding-v2\"\n",
    "encoding = tiktoken.get_encoding(MODEL_2_ENCODING[model_name])\n",
    "tokens = encoding.encode(md_str)\n",
    "print(f\"{len(tokens)} tokens\")\n",
    "print(tokens[0], tokens[1])\n",
    "\n",
    "if len(tokens) > MAX_TOKEN[model_name]:\n",
    "    print(f\"{len(tokens)} tokens exceeds the maximum of {MAX_TOKEN[model_name]} tokens\")\n",
    "    print(f\"{len(tokens)} tokens need to chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='cd06846b-aab4-4417-bfac-204838fb3bc1', metadata={'source': 'https://example.com'}, page_content='The powerhouse of the cell is the mitochondria'), Document(id='d6e7bb82-9b9f-4ff7-8404-96e24300295b', metadata={'source': 'https://example.com'}, page_content='Mitochondria are made out of lipids')]\n",
      "[Document(id='cd06846b-aab4-4417-bfac-204838fb3bc1', metadata={'source': 'https://example.com'}, page_content='The powerhouse of the cell is the mitochondria'), Document(id='9226e3c3-7c81-4f08-9909-3ba4e066c9db', metadata={'source': 'https://example.com'}, page_content='Buildings are made out of brick')]\n"
     ]
    }
   ],
   "source": [
    "# retriever with MMR\n",
    "from langchain_community.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# init qwen model config\n",
    "_ = load_dotenv(find_dotenv(\"./env/.env\"))\n",
    "\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v3\")\n",
    "vectorStore = InMemoryVectorStore(embeddings)\n",
    "\n",
    "document1 = Document(page_content=\"The powerhouse of the cell is the mitochondria\", metadata={ \"source\": \"https://example.com\" })\n",
    "document2 = Document(page_content=\"Buildings are made out of brick\", metadata={ \"source\": \"https://example.com\" })\n",
    "document3 = Document(page_content=\"Mitochondria are made out of lipids\", metadata={ \"source\": \"https://example.com\" })\n",
    "documents = [document1, document2, document3]\n",
    "\n",
    "vectorStore.add_documents(documents)\n",
    "\n",
    "simi_ret = vectorStore.similarity_search(\"biology\", k=2)\n",
    "print(simi_ret)\n",
    "\n",
    "mmr_ret = vectorStore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2, \"lambda_mult\": 0.5}).invoke(\"biology\")\n",
    "print(mmr_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\n",
      "langchain 0.3.0 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.3.11 which is incompatible.\n",
      "langchain-anthropic 0.1.23 requires langchain-core<0.3.0,>=0.2.26, but you have langchain-core 0.3.41 which is incompatible.\n",
      "langchain-community 0.3.0 requires langsmith<0.2.0,>=0.1.112, but you have langsmith 0.3.11 which is incompatible.\n",
      "langchain-experimental 0.0.64 requires langchain-community<0.3.0,>=0.2.10, but you have langchain-community 0.3.0 which is incompatible.\n",
      "langchain-experimental 0.0.64 requires langchain-core<0.3.0,>=0.2.27, but you have langchain-core 0.3.41 which is incompatible.\n",
      "langchain-google-genai 1.0.10 requires langchain-core<0.3,>=0.2.33, but you have langchain-core 0.3.41 which is incompatible.\n",
      "langchain-openai 0.1.23 requires langchain-core<0.3.0,>=0.2.35, but you have langchain-core 0.3.41 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  lark langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.vectorstores import DashVector\n",
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# init qwen model config\n",
    "_ = load_dotenv(find_dotenv(\"./env/.env\"))\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"thriller\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v3\")\n",
    "# in-memory vector store\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "vector_store.add_documents(documents)\n",
    "# sqlite vector store with local storage\n",
    "vector_store = SQLiteVSS.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    table=\"movies\",\n",
    "    db_file=\"./vss-self-query.db\",\n",
    ")\n",
    "# dashscope vector store service\n",
    "vector_store = DashVector.from_documents(docs, embeddings)\n",
    "\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"Brief summary of a movie\"\n",
    "llm_model = \"qwen-max\"\n",
    "llm = ChatTongyi(temperature=0.8, model=llm_model)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vector_store,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")\n",
    "\n",
    "# This example only specifies a filter\n",
    "retriever.invoke(\"I want to watch a movie rated higher than 8.5\")\n",
    "\n",
    "# This example specifies a query and a filter\n",
    "retriever.invoke(\"Has Greta Gerwig directed any movies about women\")\n",
    "\n",
    "# This example specifies a composite filter\n",
    "retriever.invoke(\"What's a highly rated (above 8.5) science fiction film?\")\n",
    "\n",
    "# This example specifies a query and composite filter\n",
    "retriever.invoke(\n",
    "    \"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lark in /Users/edony/code/Mentis/venv/lib/python3.10/site-packages (1.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your goal is to structure the user's query to match the request schema provided below.\n",
      "\n",
      "<< Structured Request Schema >>\n",
      "When responding use a markdown code snippet with a JSON object formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"query\": string \\ text string to compare to document contents\n",
      "    \"filter\": string \\ logical condition statement for filtering documents\n",
      "}\n",
      "```\n",
      "\n",
      "The query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\n",
      "\n",
      "A logical condition statement is composed of one or more comparison and logical operation statements.\n",
      "\n",
      "A comparison statement takes the form: `comp(attr, val)`:\n",
      "- `comp` (eq | ne | gt | gte | lt | lte | contain | like | in | nin): comparator\n",
      "- `attr` (string):  name of attribute to apply the comparison to\n",
      "- `val` (string): is the comparison value\n",
      "\n",
      "A logical operation statement takes the form `op(statement1, statement2, ...)`:\n",
      "- `op` (and | or | not): logical operator\n",
      "- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\n",
      "\n",
      "Make sure that you only use the comparators and logical operators listed above and no others.\n",
      "Make sure that filters only refer to attributes that exist in the data source.\n",
      "Make sure that filters only use the attributed names with its function names if there are functions applied on them.\n",
      "Make sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\n",
      "Make sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\n",
      "Make sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\n",
      "\n",
      "<< Example 1. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"content\": \"Lyrics of a song\",\n",
      "    \"attributes\": {\n",
      "        \"artist\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Name of the song artist\"\n",
      "        },\n",
      "        \"length\": {\n",
      "            \"type\": \"integer\",\n",
      "            \"description\": \"Length of the song in seconds\"\n",
      "        },\n",
      "        \"genre\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\n",
      "    \"query\": \"teenager love\",\n",
      "    \"filter\": \"and(or(eq(\\\"artist\\\", \\\"Taylor Swift\\\"), eq(\\\"artist\\\", \\\"Katy Perry\\\")), lt(\\\"length\\\", 180), eq(\\\"genre\\\", \\\"pop\\\"))\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 2. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"content\": \"Lyrics of a song\",\n",
      "    \"attributes\": {\n",
      "        \"artist\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Name of the song artist\"\n",
      "        },\n",
      "        \"length\": {\n",
      "            \"type\": \"integer\",\n",
      "            \"description\": \"Length of the song in seconds\"\n",
      "        },\n",
      "        \"genre\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What are songs that were not published on Spotify\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\n",
      "    \"query\": \"\",\n",
      "    \"filter\": \"NO_FILTER\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 3. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"content\": \"Brief summary of a movie\",\n",
      "    \"attributes\": {\n",
      "    \"genre\": {\n",
      "        \"description\": \"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    \"year\": {\n",
      "        \"description\": \"The year the movie was released\",\n",
      "        \"type\": \"integer\"\n",
      "    },\n",
      "    \"director\": {\n",
      "        \"description\": \"The name of the movie director\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    \"rating\": {\n",
      "        \"description\": \"A 1-10 rating for the movie\",\n",
      "        \"type\": \"float\"\n",
      "    }\n",
      "}\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "dummy question\n",
      "\n",
      "Structured Request:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructuredQuery(query='taxi drivers', filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='genre', value='science fiction'), Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='year', value=1990), Comparison(comparator=<Comparator.LTE: 'lte'>, attribute='year', value=1999), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='director', value='Luc Besson')]), limit=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self-query from scratch\n",
    "from langchain.chains.query_constructor.base import (\n",
    "    StructuredQueryOutputParser,\n",
    "    get_query_constructor_prompt,\n",
    ")\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# init qwen model config\n",
    "_ = load_dotenv(find_dotenv(\"./env/.env\"))\n",
    "\n",
    "document_content_description = \"Brief summary of a movie\"\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "    ),\n",
    "]\n",
    "llm_model = \"qwen-max\"\n",
    "llm = ChatTongyi(temperature=0.8, model=llm_model)\n",
    "prompt = get_query_constructor_prompt(\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")\n",
    "output_parser = StructuredQueryOutputParser.from_components()\n",
    "query_constructor = prompt | llm | output_parser\n",
    "\n",
    "print(prompt.format(query=\"dummy question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredQuery(query='taxi drivers', filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='genre', value='science fiction'), Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='year', value=1990), Comparison(comparator=<Comparator.LTE: 'lte'>, attribute='year', value=1999), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='director', value='Luc Besson')]), limit=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_constructor.invoke(\n",
    "    {\n",
    "        \"query\": \"What are some sci-fi movies from the 90's directed by Luc Besson about taxi drivers\"\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
