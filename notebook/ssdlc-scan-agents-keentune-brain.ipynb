{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_prompt = \"\"\"你精通python代码的静态检查相关的工具和原理，假设我拿到了python工具bandit扫描的结果，结果是json格式的，我需要分析这个结果从而确认是否误报，是否需要高优先级修复。\n",
    "首先，请根据给出的json数据，帮我找出总共有多少高危（Severity = HIGH）、中危（Severity = MEDIUM）、低危（Severity = LOW）的漏洞。\n",
    "\n",
    "json数据：\n",
    "```json\n",
    "{json_data}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ssdlc 安全检查结果分析器**\n",
    "\n",
    "### 步骤一，分析统计结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据你提供的 JSON 数据，我们可以统计出不同严重性级别的漏洞数量。以下是具体的统计步骤：\n",
      "\n",
      "1. **遍历 `metrics` 字段**：该字段包含了每个文件的扫描结果，其中包含了不同严重性级别的漏洞数量。\n",
      "2. **累加 `SEVERITY.HIGH`、`SEVERITY.MEDIUM` 和 `SEVERITY.LOW` 的值**：这些值分别代表高危、中危和低危漏洞的数量。\n",
      "\n",
      "下面是 Python 代码来实现这个统计：\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "# 假设你的 JSON 数据存储在一个字符串中\n",
      "json_data = '''{\n",
      "    \"errors\": [],\n",
      "    \"generated_at\": \"2024-11-27T06:55:48Z\",\n",
      "    \"metrics\": {\n",
      "        \"./brain/__init__.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/algorithm/__init__.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/algorithm/sensitize/__init__.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/algorithm/sensitize/sensiModel.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/algorithm/sensitize/sensitize.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 1},\n",
      "        \"./brain/algorithm/sensitize/sensitizer.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/algorithm/tuning/__init__.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/algorithm/tuning/base.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 1, \"SEVERITY.LOW\": 4},\n",
      "        \"./brain/algorithm/tuning/bgcs.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/algorithm/tuning/boBase.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 1},\n",
      "        \"./brain/algorithm/tuning/hord.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/algorithm/tuning/lamcts.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/algorithm/tuning/pms.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/algorithm/tuning/random.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/brain.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/common/__init__.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/common/config.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/common/dataset.py\": {\"SEVERITY.HIGH\": 1, \"SEVERITY.MEDIUM\": 4, \"SEVERITY.LOW\": 1},\n",
      "        \"./brain/common/pylog.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/common/system.py\": {\"SEVERITY.HIGH\": 1, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 1},\n",
      "        \"./brain/common/tools.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/controller/__init__.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/controller/process.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 1, \"SEVERITY.LOW\": 1},\n",
      "        \"./brain/controller/sensitize.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"./brain/controller/tuning.py\": {\"SEVERITY.HIGH\": 0, \"SEVERITY.MEDIUM\": 0, \"SEVERITY.LOW\": 0},\n",
      "        \"_totals\": {\"SEVERITY.HIGH\": 2, \"SEVERITY.MEDIUM\": 6, \"SEVERITY.LOW\": 9}\n",
      "    },\n",
      "    \"results\": [\n",
      "        # ... (省略了具体的结果项)\n",
      "    ]\n",
      "}'''\n",
      "\n",
      "# 解析 JSON 数据\n",
      "data = json.loads(json_data)\n",
      "\n",
      "# 初始化计数器\n",
      "high_count = 0\n",
      "medium_count = 0\n",
      "low_count = 0\n",
      "\n",
      "# 遍历 metrics 字段\n",
      "for file_metrics in data['metrics'].values():\n",
      "    high_count += file_metrics.get('SEVERITY.HIGH', 0)\n",
      "    medium_count += file_metrics.get('SEVERITY.MEDIUM', 0)\n",
      "    low_count += file_metrics.get('SEVERITY.LOW', 0)\n",
      "\n",
      "# 输出结果\n",
      "print(f\"High Severity: {high_count}\")\n",
      "print(f\"Medium Severity: {medium_count}\")\n",
      "print(f\"Low Severity: {low_count}\")\n",
      "```\n",
      "\n",
      "运行上述代码后，你会得到以下结果：\n",
      "\n",
      "```\n",
      "High Severity: 2\n",
      "Medium Severity: 6\n",
      "Low Severity: 9\n",
      "```\n",
      "\n",
      "这表明在你的代码中，总共有 2 个高危漏洞、6 个中危漏洞和 9 个低危漏洞。你可以根据这些信息来决定哪些漏洞需要优先修复。\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv(\"./env/.env\"))\n",
    "\n",
    "import dashscope\n",
    "from http import HTTPStatus\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "llm_model = \"qwen-max\"\n",
    "\n",
    "llm = ChatTongyi(temperature=1.0, model=llm_model)\n",
    "\n",
    "json_analysis_prompt = ChatPromptTemplate.from_template(json_prompt)\n",
    "\n",
    "with open(\"./data/keentune-brain-3.0.0/result.json\", \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "response = llm.invoke(json_analysis_prompt.format_messages(json_data=json_data))\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤二，提取高危扫描结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\\n'\n",
      " '  \"total_vulnerabilities\": {\\n'\n",
      " '    \"high_severity\": 2,\\n'\n",
      " '    \"medium_severity\": 6,\\n'\n",
      " '    \"low_severity\": 9\\n'\n",
      " '  },\\n'\n",
      " '  \"high_severity_issues\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"code\": \"55 def deleteFile(data_name):\\\\n56     if '\n",
      " 'os.path.exists(os.path.join(Config.TUNE_DATA_PATH, data_name)):\\\\n57         '\n",
      " 'os.system(\\\\\"rm -rf {}\\\\\".format(os.path.join(Config.TUNE_DATA_PATH, '\n",
      " 'data_name)))\\\\n\",\\n'\n",
      " '      \"col_offset\": 8,\\n'\n",
      " '      \"end_col_offset\": 85,\\n'\n",
      " '      \"filename\": \"./brain/common/dataset.py\",\\n'\n",
      " '      \"issue_confidence\": \"HIGH\",\\n'\n",
      " '      \"issue_cwe\": {\\n'\n",
      " '        \"id\": 78,\\n'\n",
      " '        \"name\": \"Improper Neutralization of Special Elements used in an OS '\n",
      " 'Command (\\'OS Command Injection\\')\"\\n'\n",
      " '      },\\n'\n",
      " '      \"issue_severity\": \"HIGH\",\\n'\n",
      " '      \"issue_text\": \"Starting a process with a shell, possible injection '\n",
      " 'detected, security issue.\",\\n'\n",
      " '      \"line_range\": [57],\\n'\n",
      " '      \"more_info\": '\n",
      " '\"https://bandit.readthedocs.io/en/1.8.0/plugins/b605_start_process_with_a_shell.html\",\\n'\n",
      " '      \"test_id\": \"B605\",\\n'\n",
      " '      \"test_name\": \"start_process_with_a_shell\"\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"code\": \"15     result = subprocess.run(\\\\n16         '\n",
      " 'command,\\\\n17         shell=True,\\\\n18         close_fds=True,\\\\n19         '\n",
      " 'cwd=cwd,\\\\n20         stderr=subprocess.PIPE,\\\\n21         '\n",
      " 'stdout=subprocess.PIPE\\\\n22     )\\\\n23 \\\\n24     suc = (result.returncode == '\n",
      " \"0)\\\\n25     out = result.stdout.decode('UTF-8', 'strict').strip()\\\\n26     \"\n",
      " 'error = result.stderr.decode(\\'UTF-8\\', \\'strict\\').strip()\\\\n\",\\n'\n",
      " '      \"col_offset\": 13,\\n'\n",
      " '      \"end_col_offset\": 5,\\n'\n",
      " '      \"filename\": \"./brain/common/system.py\",\\n'\n",
      " '      \"issue_confidence\": \"HIGH\",\\n'\n",
      " '      \"issue_cwe\": {\\n'\n",
      " '        \"id\": 78,\\n'\n",
      " '        \"name\": \"Improper Neutralization of Special Elements used in an OS '\n",
      " 'Command (\\'OS Command Injection\\')\"\\n'\n",
      " '      },\\n'\n",
      " '      \"issue_severity\": \"HIGH\",\\n'\n",
      " '      \"issue_text\": \"subprocess call with shell=True identified, security '\n",
      " 'issue.\",\\n'\n",
      " '      \"line_range\": [15, 16, 17, 18, 19, 20, 21, 22],\\n'\n",
      " '      \"more_info\": '\n",
      " '\"https://bandit.readthedocs.io/en/1.8.0/plugins/b602_subprocess_popen_with_shell_equals_true.html\",\\n'\n",
      " '      \"test_id\": \"B602\",\\n'\n",
      " '      \"test_name\": \"subprocess_popen_with_shell_equals_true\"\\n'\n",
      " '    }\\n'\n",
      " '  ],\\n'\n",
      " '  \"files_with_high_severity_issues\": [\\n'\n",
      " '    \"./brain/common/dataset.py\",\\n'\n",
      " '    \"./brain/common/system.py\"\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "high_risk_prompt = \"\"\"你精通python代码的静态检查相关的工具和原理，假设我拿到了python工具bandit扫描的结果，结果是json格式的，我需要分析这个结果从而确认是否误报，是否需要高优先级修复。扫描结果格式如下所示：\n",
    "```json\n",
    "{{\n",
    "  \"error\": [<检查工具报错问题列表>],\n",
    "  \"generated_at\": \"<生成报告的时间>\",\n",
    "  \"metrics\": {{\n",
    "    \"<文件名1>\": {{\n",
    "      \"CONFIDENCE.HIGH\": <当前文件中扫描出的问题信心指数高的个数>,\n",
    "      \"CONFIDENCE.LOW\": <当前文件中扫描出的问题信心指数低的个数>,\n",
    "      \"CONFIDENCE.MEDIUM\":<当前文件中扫描出的问题信心指数中的个数>,\n",
    "      \"CONFIDENCE.UNDEFINED\": <当前文件中扫描出的问题信心指数不确定的个数>,\n",
    "      \"SEVERITY.HIGH\": <当前文件中扫描出的问题严重性高的个数>,\n",
    "      \"SEVERITY.LOW\": <当前文件中扫描出的问题严重性低的个数>,\n",
    "      \"SEVERITY.MEDIUM\": <当前文件中扫描出的问题严重性的中的个数>,\n",
    "      \"SEVERITY.UNDEFINED\": <当前文件中扫描出的问题严重性不确定的个数>,\n",
    "      \"loc\": <当前文件代码行数>,\n",
    "      \"nosec\": <当前文件nosec打标数量>,\n",
    "      \"skipped_tests\": <当前文件跳过的测试数量>\n",
    "    }},\n",
    "    \"<文件名2>\": {{...}},\n",
    "    ...\n",
    "    \"<文件名n>\": {{...}},\n",
    "    \"_totals\": {{\n",
    "      \"CONFIDENCE.HIGH\": <所有文件中扫描出的问题信心指数高的个数>,\n",
    "      \"CONFIDENCE.LOW\": <所有文件中扫描出的问题信心指数低的个数>,\n",
    "      \"CONFIDENCE.MEDIUM\":<所有文件中扫描出的问题信心指数中的个数>,\n",
    "      \"CONFIDENCE.UNDEFINED\": <所有文件中扫描出的问题信心指数不确定的个数>,\n",
    "      \"SEVERITY.HIGH\": <所有文件中扫描出的问题严重性高的个数>,\n",
    "      \"SEVERITY.LOW\": <所有文件中扫描出的问题严重性低的个数>,\n",
    "      \"SEVERITY.MEDIUM\": <所有文件中扫描出的问题严重性的中的个数>,\n",
    "      \"SEVERITY.UNDEFINED\": <所有文件中扫描出的问题严重性不确定的个数>,\n",
    "      \"loc\": <所有文件代码行数>,\n",
    "      \"nosec\": <所有文件nosec打标数量>,\n",
    "      \"skipped_tests\": <所有文件跳过的测试数量>\n",
    "    }},\n",
    "    \"results\":[<检查工具扫描出的问题列表>\n",
    "    <example>\n",
    "    {{\n",
    "      \"code\": \"3 import json\\n4 import requests\\n5 import subprocess\\n6 import logging\\n7 \\n\",\n",
    "      \"col_offset\": 0,\n",
    "      \"end_col_offset\": 17,\n",
    "      \"filename\": \"./bench/common/system.py\",\n",
    "      \"issue_confidence\": \"HIGH\",\n",
    "      \"issue_cwe\": {{\n",
    "        \"id\": 78,\n",
    "        \"link\": \"https://cwe.mitre.org/data/definitions/78.html\"\n",
    "      }},\n",
    "      \"issue_severity\": \"LOW\",\n",
    "      \"issue_text\": \"Consider possible security implications associated with the subprocess module.\",\n",
    "      \"line_number\": 5,\n",
    "      \"line_range\": [\n",
    "        5\n",
    "      ],\n",
    "      \"more_info\": \"https://bandit.readthedocs.io/en/1.8.0/blacklists/blacklist_imports.html#b404-import-subprocess\",\n",
    "      \"test_id\": \"B404\",\n",
    "      \"test_name\": \"blacklist\"\n",
    "    }}\n",
    "    </example>\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "```\n",
    "\n",
    "你需要做的事情是：\n",
    "1.请根据给出的json数据，帮我找出总共有多少高危（Severity = HIGH）、中危（Severity = MEDIUM）、低危（Severity = LOW）的漏洞。\n",
    "2.输出扫描结果中高危的问题列表。\n",
    "3.根据扫描结果中metrics记录，帮我找出扫描结果中，存在高危漏洞的文件列表。\n",
    "\n",
    "要求：\n",
    "1.根据我的要求帮我完成上述任务，不要做其他事情。\n",
    "2.不需要输出任何解释，只需要按照我的要求做完事就好。\n",
    "3.输出必须是json格式，包括扫描结果的总数量和问题列表。\n",
    "4.输出结果不需要包括```json, ```这样符号。\n",
    "5.输出格式如下：\n",
    "```json\n",
    "{{\n",
    "  \"total_vulnerabilities\":{{\n",
    "    \"high_severity\": <高危问题数量>,\n",
    "    \"medium_severity\": <中危问题数量>,\n",
    "    \"low_severity\": <低危问题数量>,\n",
    "  }},\n",
    "  \"high_severity_issues\": [\n",
    "    {{\n",
    "      \"code\": <问题代码>,\n",
    "      \"col_offset\": <问题的描述>,\n",
    "      \"end_col_offset\": <问题的严重程度>,\n",
    "      \"filename\": <问题的修复建议>,\n",
    "      \"issue_confidence\": <参考资料链接>,\n",
    "      \"issue_cwe\": {{\n",
    "        \"id\": <CWE编号>,\n",
    "        \"name\": <CWE名称>\n",
    "      }},\n",
    "      \"issue_severity\": <问题严重等级>,\n",
    "      \"issue_text\": <问题描述>,\n",
    "      \"line_range\": <问题所在行>,\n",
    "      \"more_info\": <问题修复建议>,\n",
    "      \"test_id\": <问题类型>,\n",
    "      \"test_name\": <问题类型名称>\n",
    "    }},\n",
    "    ...\n",
    "  ],\n",
    "  \"files_with_high_severity_issues\": [\n",
    "    <文件路径>,\n",
    "    ...\n",
    "  ],\n",
    "}}\n",
    "```\n",
    "\n",
    "json数据：\n",
    "```json\n",
    "{json_data}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "high_risk_analysis_prompt = ChatPromptTemplate.from_template(high_risk_prompt)\n",
    "\n",
    "response = llm.invoke(high_risk_analysis_prompt.format_messages(json_data=json_data))\n",
    "\n",
    "high_risk = response.content\n",
    "pprint(\"\".join(high_risk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤三，提取高危问题源码和CWE信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_data = json.loads(high_risk)\n",
    "risk_code = risk_data[\"high_severity_issues\"][0][\"code\"]\n",
    "\n",
    "import os\n",
    "source_code_files = [\"agent/common/macro.py\", \"agent/common/netinfo.py\", \"agent/controller/status.py\", \"agent/domain/cpu.py\", \"agent/feature/affinity.py\", \"agent/feature/alpm.py\", \"agent/feature/code_hugepage.py\", \"agent/feature/combined.py\", \"agent/feature/readahead.py\", \"agent/feature/rps.py\", \"agent/feature/transparent_hugepages_defrag.py\", \"agent/feature/transparent_hugepages.py\", \"agent/feature/xps.py\"]\n",
    "source_code_paths = [os.path.join(\"./data\", \"keentune-target-3.2.0\", code_file) for code_file in source_code_files]\n",
    "cwd_78_path = os.path.join(\"./data\", \"cwe-78.md\")\n",
    "\n",
    "source_codes = [open(source_code_path, \"r\").read() for source_code_path in source_code_paths]\n",
    "cwe_78 = open(cwd_78_path, \"r\").read()\n",
    "from IPython.display import display,Markdown\n",
    "display(Markdown(\n",
    "f\"\"\"```python\n",
    "{risk_code}\n",
    "```\n",
    "---\n",
    "```python\n",
    "{source_codes[0]}\n",
    "```\n",
    "...\n",
    "---\n",
    "{cwe_78[:2000]}\n",
    "\n",
    "...\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤四，提取高危源码的调用关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "parse_high_risk_call_graph_template = \"\"\"你是一个精通python语言分析的专家，我会给你一段含有python代码高危问题的json数据，数据格式为：\n",
    "```json\n",
    "{{\n",
    "  \"total_vulnerabilities\":{{\n",
    "    \"high_severity\": <高危问题数量>,\n",
    "    \"medium_severity\": <中危问题数量>,\n",
    "    \"low_severity\": <低危问题数量>,\n",
    "  }},\n",
    "  \"high_severity_issues\": [\n",
    "    {{\n",
    "      \"code\": <问题代码>,\n",
    "      \"col_offset\": <问题的描述>,\n",
    "      \"end_col_offset\": <问题的严重程度>,\n",
    "      \"filename\": <问题的修复建议>,\n",
    "      \"issue_confidence\": <参考资料链接>,\n",
    "      \"issue_cwe\": {{\n",
    "        \"id\": <CWE编号>,\n",
    "        \"name\": <CWE名称>\n",
    "      }},\n",
    "      \"issue_severity\": <问题严重等级>,\n",
    "      \"issue_text\": <问题描述>,\n",
    "      \"line_range\": <问题所在行>,\n",
    "      \"more_info\": <问题修复建议>,\n",
    "      \"test_id\": <问题类型>,\n",
    "      \"test_name\": <问题类型名称>\n",
    "    }},\n",
    "    ...\n",
    "  ],\n",
    "  \"files_with_high_severity_issues\": [\n",
    "    <文件路径>,\n",
    "    ...\n",
    "  ],\n",
    "}}\n",
    "```\n",
    "\n",
    "python代码高危问题json数据为：\n",
    "{high_risk}\n",
    "\n",
    "同时我还会提供源码内容{source_code}以供你进行python的分析。\n",
    "\n",
    "你需要做的事情是：\n",
    "1.找出问题代码段在源码文件中属于哪个函数\n",
    "2.找出第1步中函数调用链\n",
    "\"\"\"\n",
    "\n",
    "parse_high_risk_call_graph_prompt = ChatPromptTemplate.from_template(\n",
    "    parse_high_risk_call_graph_template\n",
    ")\n",
    "\n",
    "high_risk_call_graphs = []\n",
    "\n",
    "for source_code in source_codes:\n",
    "  response = llm.invoke(\n",
    "      parse_high_risk_call_graph_prompt.format_messages(high_risk=high_risk, source_code=source_code)\n",
    "  )\n",
    "\n",
    "  high_risk_call_graph = response.content\n",
    "  high_risk_call_graphs.append(high_risk_call_graph)\n",
    "  print(high_risk_call_graph)\n",
    "\n",
    "\n",
    "  dot_graph_description = \"\"\"你是一个精通DOT语言描述代码调用关系图（call graph）的专家，请根据我给出的python代码高危问题json数据和高危问题所在函数及其调用点数据，用dot语言描述该代码调用关系图。\n",
    "\n",
    "**要求：**\n",
    "1.你不需要做其他任何事情，只需要用dot语言把代码调用关系图出来就可以；\n",
    "2.你可以根据自己对dot语言的理解进行编写生成dot语言描述，但请确保你的描述符合dot语言语法，并且能正确描述出代码调用关系图；\n",
    "3.你的描述需要包含函数名、函数参数、函数返回值、函数调用链、参数样例等必要信息，但不要包含函数体；\n",
    "4.如果dot语言描述过程中遇到存在高危问题的函数时，通过设置节点颜色为淡红色的方式来突出该节点，其他节点保持黑底白字即可；\n",
    "5.生成的内容除了dot语言之外不要包括其他任何内容，也不要包含```dot和```这类非dot语言语法的内容；\n",
    "\n",
    "\n",
    "python代码高危问题json数据为：\n",
    "{high_risk}\n",
    "\n",
    "高危问题所在函数及其调用点数据为：\n",
    "{high_risk_call_graph}\n",
    "\"\"\"\n",
    "  dot_graph_prompt = ChatPromptTemplate.from_template(dot_graph_description)\n",
    "\n",
    "  response = llm.invoke(\n",
    "    dot_graph_prompt.format_messages(high_risk=high_risk, high_risk_call_graph=high_risk_call_graph)\n",
    "  )\n",
    "\n",
    "  dot_graph = response.content\n",
    "\n",
    "  print(dot_graph)\n",
    "\n",
    "  dot_call_graph = Source(dot_graph, filename=\"output-graph.gv\", format=\"svg\")\n",
    "  display(SVG(dot_call_graph.pipe().decode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤五，CWE危险等级分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for risk in risk_data[\"high_severity_issues\"]:\n",
    "    print(risk['issue_cwe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwe_severity_analysis_template = \"\"\"你是一个精通python语言的安全工程师，你精通CWE漏洞的利用。我会给出一段有高危问题的源码和高危问题所在函数的调用链，同时我还会给出高危问题的CWE信息，\n",
    "CWE信息包括：\n",
    "- CWE名称\n",
    "- CWE编号（Weakness ID）\n",
    "- CWE描述（Description， Extended Description）\n",
    "- CWE常见的后果（Common Consequence）\n",
    "- CWE修复建议（Potential Mitigations），修复建议会根据不同阶段Phase给出办法，例如：架构设计阶段Phase: Architecture and Design\n",
    "\n",
    "你的任务是根据CWE信息对高危问题进行分析：\n",
    "1.根据高危问题以及其函数调用链的信息，结合CWE信息，给出该问题的影响和后果；\n",
    "2.根据函数调用链信息以及源码，结合CWE描述和修复建议等信息，给出该高危问题被外部调用者利用的可能性和难易程度；\n",
    "3.根据CWE的修复建议、函数调用链、该高危问题被利用的可能性和难易程度，给出该高危问题的修复建议；\n",
    "4.根据上面步骤1，2，3的分析结果，给出该高危问题的分析总结；\n",
    "\n",
    "要求：\n",
    "- 输出结果的标题为\"SSDLC高危问题分析报告\"；\n",
    "- 需要按照分析过程进行内容输出，包括：1.问题的影响和后果；2.利用的可能性和难易程度；3.修复建议；4.分析总结；\n",
    "- 输出结果时需要按照分析过程包括你使用的数据来源，分析方法，以及你如何结合CWE信息对问题的影响和后果进行评估；\n",
    "- 给出的修复建议中要考虑函数调用链上每个函数的参数和返回值；\n",
    "- 为了方便快速识别和理解该高危问题，高危问题分析总结中，根据该高危问题被外部调用者利用的可能性是由高到低、难易程度由容易到困难以及修复问题的难度由简单到困难，给出总结评估打分；\n",
    "\n",
    "高危问题所在源码：\n",
    "```python\n",
    "{source_code}\n",
    "```\n",
    "\n",
    "高危问题所在函数调用链情况：\n",
    "```python\n",
    "{high_risk_call_graph}\n",
    "```\n",
    "\n",
    "CWE信息如下：\n",
    "```markdown\n",
    "{cwe_info}\n",
    "```\n",
    "\"\"\"\n",
    "all_cwe_severity_analysis = {}\n",
    "for i in range(len(source_codes)):  \n",
    "    cwe_severity_analysis_prompt = ChatPromptTemplate.from_template(\n",
    "        cwe_severity_analysis_template\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(\n",
    "        cwe_severity_analysis_prompt.format_messages(\n",
    "            source_code=source_codes[i],\n",
    "            high_risk_call_graph=high_risk_call_graphs[i],\n",
    "            cwe_info=cwe_78,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    cwe_severity_analysis = response.content\n",
    "    all_cwe_severity_analysis[source_code_paths[i]] = cwe_severity_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤六，生成ssdlc扫描分析报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for souce_code_path, cwe_severity_analisys in all_cwe_severity_analysis.items():\n",
    "    display(Markdown(f\"---\\n### {souce_code_path}\\n---\"))\n",
    "    display(Markdown(cwe_severity_analysis))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
